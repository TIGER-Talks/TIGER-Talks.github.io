---
title: LLMs can be Fooled into Labelling a Document as Relevant

event: TIGER Talk
event_url: https://example.org

location: RMIT University & Online
address:
  street: 124 La Trobe St
  city: Melbourne
  region: VIC
  postcode: '3000'
  country: Australia

summary: Marwah Alaofi presents her **SIGIR-AP 2024 Best Paper** on how Large Language Models can be fooled into labelling a document as relevant.
abstract: 'Large Language Models ( LLM s) are increasingly being used to assess the relevance of information objects. 
        This work reports on experiments to study the labelling of short texts (i.e., passages) for relevance, using 
        multiple open-source and proprietary LLMs. While the overall agreement of some LLM s with human judgements is
        comparable to human-to-human agreement measured in previous research, LLM s are more likely to label passages
        as relevant compared to human judges, indicating that LLM labels denoting non-relevance are more reliable than
        those indicating relevance.'

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: '2025-02-14T12:00:00+11:00'
date_end: '2025-02-14T13:00:00+11:00'
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: '2025-01-14T12:00:00+11:00'

authors: [admin]
tags: [Talk, IR, LLM, SIGIR-AP, Relevance, Labelling]

# Is this a featured talk? (true/false)
featured: true

image:
  caption: 'Photo by [Victor Serban](https://unsplash.com/@victorserban?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash") on [Unsplash](https://unsplash.com/photos/woman-in-blue-and-white-dress-SgAqgz9tEKw?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash")'
  focal_point: Right

url_code: ''
url_pdf: 'https://dl.acm.org/doi/pdf/10.1145/3673791.3698431'
url_slides: ''
url_video: ''

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides:

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects:
---

**Speaker:** [Marwah Alaofi](https://marwahalaofi.com/)

**Date:** 14th February 2025

**Time:** 12:00 PM - 1:00 PM

**Location:** RMIT University & Online

**Abstract:**
Large Language Models ( LLM s) are increasingly being used to assess the relevance of information objects. 
This work reports on experiments to study the labelling of short texts (i.e., passages) for relevance, using 
multiple open-source and proprietary LLMs. While the overall agreement of some LLM s with human judgements is
comparable to human-to-human agreement measured in previous research, LLM s are more likely to label passages
as relevant compared to human judges, indicating that LLM labels denoting non-relevance are more reliable than
those indicating relevance.

{{% cta cta_link="./talks/" cta_text="Register Now â†’" cta_new_tab="true" %}}
